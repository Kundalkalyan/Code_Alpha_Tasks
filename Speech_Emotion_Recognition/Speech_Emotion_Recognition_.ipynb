{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import librosa\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa.display\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Conv2D,MaxPooling2D,Flatten,Dropout,BatchNormalization\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4lX4o5Zykb6Y"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotion_dict ={\n",
        "  '01':'Neutral',\n",
        "  '02':'Calm',\n",
        "  '03':'happy',\n",
        "  '04':'Sad',\n",
        "  '05':'angry',\n",
        "  '06':'Fear',\n",
        "  '07':'Disgust',\n",
        "  '08':'suprise',\n",
        "}"
      ],
      "metadata": {
        "id": "J9kLWRZ0y3Zm"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_mfcc(file_path):\n",
        "    audio, sr = librosa.load(file_path, duration=3, offset=0.5)\n",
        "    mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=40)\n",
        "    return np.mean(mfcc.T, axis=0)\n"
      ],
      "metadata": {
        "id": "WbgffIQ119tw"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hpSmHuJ6egYk",
        "outputId": "faa89bb3-6ec6-4c0b-cdb0-4eef9cd4a408"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = []\n",
        "y = []\n",
        "\n",
        "data_path = \"/content/audio_speech_actors_01-24\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for actor in os.listdir(data_path):\n",
        "    actor_path = os.path.join(data_path, actor)\n",
        "\n",
        "    for file in os.listdir(actor_path):\n",
        "        file_path = os.path.join(actor_path, file)\n",
        "\n",
        "        emotion = file.split(\"-\")[2]\n",
        "\n",
        "        X.append(extract_mfcc(file_path))\n",
        "        y.append(emotion)\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n"
      ],
      "metadata": {
        "id": "Vlnv7cJH2V-G"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "data_path = \"/content/audio_speech_actors_01-24\"\n",
        "\n",
        "for actor in os.listdir(data_path):\n",
        "    actor_path = os.path.join(data_path, actor)\n",
        "    print(actor_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJe9pGPIfGKL",
        "outputId": "c1212cb9-612e-42c8-816f-7f165d5554a3"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/audio_speech_actors_01-24/Actor_24\n",
            "/content/audio_speech_actors_01-24/Actor_12\n",
            "/content/audio_speech_actors_01-24/Actor_11\n",
            "/content/audio_speech_actors_01-24/Actor_20\n",
            "/content/audio_speech_actors_01-24/Actor_19\n",
            "/content/audio_speech_actors_01-24/Actor_09\n",
            "/content/audio_speech_actors_01-24/Actor_18\n",
            "/content/audio_speech_actors_01-24/Actor_21\n",
            "/content/audio_speech_actors_01-24/Actor_10\n",
            "/content/audio_speech_actors_01-24/Actor_02\n",
            "/content/audio_speech_actors_01-24/Actor_22\n",
            "/content/audio_speech_actors_01-24/Actor_13\n",
            "/content/audio_speech_actors_01-24/Actor_15\n",
            "/content/audio_speech_actors_01-24/Actor_01\n",
            "/content/audio_speech_actors_01-24/Actor_17\n",
            "/content/audio_speech_actors_01-24/Actor_05\n",
            "/content/audio_speech_actors_01-24/Actor_23\n",
            "/content/audio_speech_actors_01-24/Actor_08\n",
            "/content/audio_speech_actors_01-24/Actor_07\n",
            "/content/audio_speech_actors_01-24/Actor_06\n",
            "/content/audio_speech_actors_01-24/Actor_04\n",
            "/content/audio_speech_actors_01-24/Actor_16\n",
            "/content/audio_speech_actors_01-24/Actor_03\n",
            "/content/audio_speech_actors_01-24/Actor_14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n"
      ],
      "metadata": {
        "id": "EeCPiCdmb4ls"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = LabelEncoder()\n",
        "y_encoded = encoder.fit_transform(y)\n",
        "y_categorical = to_categorical(y_encoded)\n"
      ],
      "metadata": {
        "id": "OoygYypiGnTF"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y_categorical, test_size=0.2, random_state=42\n",
        ")\n"
      ],
      "metadata": {
        "id": "2UlJYM9gHXxv"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(512, input_shape=(40,), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "\n",
        "model.add(Dense(8, activation='softmax'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7SOpxgt2Xvk",
        "outputId": "9deaecc6-5332-4256-aa19-b32233ad1052"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YW8Nc_KeXz3j",
        "outputId": "37d6341a-5203-4bbc-ef51-68e8babb5cd2"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1152, 40)\n",
            "(1152, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")\n"
      ],
      "metadata": {
        "id": "volE_x6ofYJz"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=200,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_test, y_test)\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IfaMtvovIrcg",
        "outputId": "598f1327-7a38-4d10-97c1-584fa7ada41b"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.2004 - loss: 2.2873 - val_accuracy: 0.3160 - val_loss: 1.9033\n",
            "Epoch 2/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3690 - loss: 1.6726 - val_accuracy: 0.3750 - val_loss: 1.7796\n",
            "Epoch 3/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5100 - loss: 1.3590 - val_accuracy: 0.3889 - val_loss: 1.6649\n",
            "Epoch 4/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5575 - loss: 1.2336 - val_accuracy: 0.5139 - val_loss: 1.5196\n",
            "Epoch 5/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5800 - loss: 1.1314 - val_accuracy: 0.5104 - val_loss: 1.3918\n",
            "Epoch 6/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5961 - loss: 1.0240 - val_accuracy: 0.5799 - val_loss: 1.2846\n",
            "Epoch 7/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6310 - loss: 0.9804 - val_accuracy: 0.5903 - val_loss: 1.1885\n",
            "Epoch 8/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6674 - loss: 0.9572 - val_accuracy: 0.6076 - val_loss: 1.1544\n",
            "Epoch 9/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7094 - loss: 0.8404 - val_accuracy: 0.6146 - val_loss: 1.1127\n",
            "Epoch 10/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7080 - loss: 0.8139 - val_accuracy: 0.6181 - val_loss: 1.0660\n",
            "Epoch 11/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7432 - loss: 0.6992 - val_accuracy: 0.6632 - val_loss: 0.9747\n",
            "Epoch 12/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7653 - loss: 0.6418 - val_accuracy: 0.6597 - val_loss: 1.0061\n",
            "Epoch 13/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7627 - loss: 0.6571 - val_accuracy: 0.6875 - val_loss: 0.9189\n",
            "Epoch 14/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7726 - loss: 0.6500 - val_accuracy: 0.6458 - val_loss: 0.9695\n",
            "Epoch 15/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7918 - loss: 0.5911 - val_accuracy: 0.6910 - val_loss: 0.9707\n",
            "Epoch 16/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8119 - loss: 0.4952 - val_accuracy: 0.6875 - val_loss: 0.9782\n",
            "Epoch 17/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7926 - loss: 0.5797 - val_accuracy: 0.7049 - val_loss: 0.9041\n",
            "Epoch 18/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8318 - loss: 0.5047 - val_accuracy: 0.7292 - val_loss: 0.8585\n",
            "Epoch 19/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8419 - loss: 0.4676 - val_accuracy: 0.7049 - val_loss: 0.9116\n",
            "Epoch 20/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8118 - loss: 0.5494 - val_accuracy: 0.6840 - val_loss: 0.9166\n",
            "Epoch 21/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8462 - loss: 0.4128 - val_accuracy: 0.7049 - val_loss: 0.9121\n",
            "Epoch 22/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8405 - loss: 0.4437 - val_accuracy: 0.6979 - val_loss: 0.8784\n",
            "Epoch 23/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8379 - loss: 0.4503 - val_accuracy: 0.7118 - val_loss: 0.9525\n",
            "Epoch 24/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8376 - loss: 0.3884 - val_accuracy: 0.7118 - val_loss: 0.8989\n",
            "Epoch 25/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8503 - loss: 0.3960 - val_accuracy: 0.6667 - val_loss: 0.9401\n",
            "Epoch 26/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8459 - loss: 0.4101 - val_accuracy: 0.7014 - val_loss: 0.9115\n",
            "Epoch 27/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8729 - loss: 0.3841 - val_accuracy: 0.7153 - val_loss: 0.9296\n",
            "Epoch 28/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8534 - loss: 0.3816 - val_accuracy: 0.7118 - val_loss: 0.8650\n",
            "Epoch 29/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8701 - loss: 0.3390 - val_accuracy: 0.6840 - val_loss: 0.8920\n",
            "Epoch 30/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9043 - loss: 0.2839 - val_accuracy: 0.7049 - val_loss: 0.8970\n",
            "Epoch 31/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8869 - loss: 0.3009 - val_accuracy: 0.7118 - val_loss: 0.9983\n",
            "Epoch 32/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8905 - loss: 0.3045 - val_accuracy: 0.7292 - val_loss: 0.8761\n",
            "Epoch 33/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8931 - loss: 0.2793 - val_accuracy: 0.7083 - val_loss: 0.9409\n",
            "Epoch 34/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9145 - loss: 0.2542 - val_accuracy: 0.7153 - val_loss: 0.9986\n",
            "Epoch 35/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9225 - loss: 0.2323 - val_accuracy: 0.7153 - val_loss: 0.9388\n",
            "Epoch 36/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9032 - loss: 0.2641 - val_accuracy: 0.7188 - val_loss: 0.9874\n",
            "Epoch 37/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9179 - loss: 0.2350 - val_accuracy: 0.7118 - val_loss: 0.9745\n",
            "Epoch 38/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8983 - loss: 0.2926 - val_accuracy: 0.7326 - val_loss: 0.9241\n",
            "Epoch 39/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9123 - loss: 0.2309 - val_accuracy: 0.7222 - val_loss: 0.8340\n",
            "Epoch 40/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9359 - loss: 0.2007 - val_accuracy: 0.7188 - val_loss: 0.9843\n",
            "Epoch 41/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9309 - loss: 0.2103 - val_accuracy: 0.7361 - val_loss: 0.9080\n",
            "Epoch 42/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9345 - loss: 0.1844 - val_accuracy: 0.7361 - val_loss: 0.9555\n",
            "Epoch 43/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9005 - loss: 0.2535 - val_accuracy: 0.7083 - val_loss: 0.9536\n",
            "Epoch 44/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8833 - loss: 0.3256 - val_accuracy: 0.7257 - val_loss: 0.9134\n",
            "Epoch 45/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9083 - loss: 0.2587 - val_accuracy: 0.7188 - val_loss: 0.9149\n",
            "Epoch 46/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9372 - loss: 0.1912 - val_accuracy: 0.7292 - val_loss: 0.9835\n",
            "Epoch 47/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9254 - loss: 0.2089 - val_accuracy: 0.6910 - val_loss: 0.9935\n",
            "Epoch 48/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9276 - loss: 0.2036 - val_accuracy: 0.7326 - val_loss: 0.9907\n",
            "Epoch 49/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9284 - loss: 0.2118 - val_accuracy: 0.7292 - val_loss: 0.9987\n",
            "Epoch 50/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9661 - loss: 0.1430 - val_accuracy: 0.7292 - val_loss: 0.9192\n",
            "Epoch 51/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9229 - loss: 0.2249 - val_accuracy: 0.7778 - val_loss: 0.8301\n",
            "Epoch 52/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9298 - loss: 0.2091 - val_accuracy: 0.7639 - val_loss: 0.9721\n",
            "Epoch 53/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9250 - loss: 0.2172 - val_accuracy: 0.7396 - val_loss: 0.9784\n",
            "Epoch 54/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9345 - loss: 0.1952 - val_accuracy: 0.7222 - val_loss: 0.9611\n",
            "Epoch 55/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9303 - loss: 0.1992 - val_accuracy: 0.7500 - val_loss: 0.9109\n",
            "Epoch 56/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9562 - loss: 0.1401 - val_accuracy: 0.7257 - val_loss: 1.0273\n",
            "Epoch 57/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9336 - loss: 0.2011 - val_accuracy: 0.7361 - val_loss: 0.9377\n",
            "Epoch 58/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9483 - loss: 0.1587 - val_accuracy: 0.7535 - val_loss: 0.9720\n",
            "Epoch 59/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9286 - loss: 0.1933 - val_accuracy: 0.7326 - val_loss: 0.9199\n",
            "Epoch 60/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9400 - loss: 0.1763 - val_accuracy: 0.7326 - val_loss: 0.9910\n",
            "Epoch 61/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9593 - loss: 0.1508 - val_accuracy: 0.6771 - val_loss: 1.1725\n",
            "Epoch 62/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9440 - loss: 0.1552 - val_accuracy: 0.7361 - val_loss: 0.9810\n",
            "Epoch 63/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9417 - loss: 0.1485 - val_accuracy: 0.7431 - val_loss: 1.0088\n",
            "Epoch 64/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9426 - loss: 0.1607 - val_accuracy: 0.7569 - val_loss: 1.0459\n",
            "Epoch 65/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9308 - loss: 0.2007 - val_accuracy: 0.7465 - val_loss: 0.9358\n",
            "Epoch 66/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9400 - loss: 0.1672 - val_accuracy: 0.7292 - val_loss: 1.0294\n",
            "Epoch 67/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9370 - loss: 0.1788 - val_accuracy: 0.7708 - val_loss: 0.9495\n",
            "Epoch 68/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9526 - loss: 0.1563 - val_accuracy: 0.7604 - val_loss: 0.9813\n",
            "Epoch 69/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9459 - loss: 0.1537 - val_accuracy: 0.7639 - val_loss: 0.9505\n",
            "Epoch 70/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9477 - loss: 0.1406 - val_accuracy: 0.7500 - val_loss: 1.0301\n",
            "Epoch 71/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9378 - loss: 0.1430 - val_accuracy: 0.7257 - val_loss: 1.0147\n",
            "Epoch 72/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9403 - loss: 0.1608 - val_accuracy: 0.7604 - val_loss: 0.8717\n",
            "Epoch 73/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9340 - loss: 0.1594 - val_accuracy: 0.7431 - val_loss: 0.9831\n",
            "Epoch 74/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9350 - loss: 0.1840 - val_accuracy: 0.7257 - val_loss: 1.0014\n",
            "Epoch 75/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9534 - loss: 0.1292 - val_accuracy: 0.7396 - val_loss: 1.1077\n",
            "Epoch 76/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9569 - loss: 0.1108 - val_accuracy: 0.7326 - val_loss: 1.0927\n",
            "Epoch 77/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9467 - loss: 0.1472 - val_accuracy: 0.7292 - val_loss: 1.0189\n",
            "Epoch 78/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9418 - loss: 0.1533 - val_accuracy: 0.7361 - val_loss: 1.0229\n",
            "Epoch 79/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9528 - loss: 0.1399 - val_accuracy: 0.7118 - val_loss: 1.0076\n",
            "Epoch 80/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9568 - loss: 0.1402 - val_accuracy: 0.7431 - val_loss: 0.9752\n",
            "Epoch 81/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9473 - loss: 0.1774 - val_accuracy: 0.7500 - val_loss: 0.9801\n",
            "Epoch 82/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9661 - loss: 0.1110 - val_accuracy: 0.7639 - val_loss: 0.8667\n",
            "Epoch 83/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9597 - loss: 0.1345 - val_accuracy: 0.7639 - val_loss: 0.9929\n",
            "Epoch 84/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9442 - loss: 0.1549 - val_accuracy: 0.7674 - val_loss: 0.9899\n",
            "Epoch 85/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9634 - loss: 0.1100 - val_accuracy: 0.7396 - val_loss: 0.9847\n",
            "Epoch 86/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9568 - loss: 0.1256 - val_accuracy: 0.7604 - val_loss: 0.9241\n",
            "Epoch 87/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9611 - loss: 0.1030 - val_accuracy: 0.7604 - val_loss: 0.9275\n",
            "Epoch 88/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9535 - loss: 0.1435 - val_accuracy: 0.7674 - val_loss: 0.9601\n",
            "Epoch 89/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9505 - loss: 0.1393 - val_accuracy: 0.7431 - val_loss: 0.9854\n",
            "Epoch 90/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9716 - loss: 0.0941 - val_accuracy: 0.7153 - val_loss: 1.0482\n",
            "Epoch 91/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9552 - loss: 0.1440 - val_accuracy: 0.7500 - val_loss: 1.0243\n",
            "Epoch 92/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9470 - loss: 0.1457 - val_accuracy: 0.7292 - val_loss: 1.1096\n",
            "Epoch 93/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9537 - loss: 0.1544 - val_accuracy: 0.7604 - val_loss: 1.0369\n",
            "Epoch 94/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9621 - loss: 0.1117 - val_accuracy: 0.7396 - val_loss: 0.9945\n",
            "Epoch 95/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9592 - loss: 0.1223 - val_accuracy: 0.7465 - val_loss: 1.0241\n",
            "Epoch 96/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9666 - loss: 0.1047 - val_accuracy: 0.7431 - val_loss: 1.0408\n",
            "Epoch 97/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9654 - loss: 0.1190 - val_accuracy: 0.7639 - val_loss: 1.0902\n",
            "Epoch 98/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9655 - loss: 0.1069 - val_accuracy: 0.7500 - val_loss: 1.0553\n",
            "Epoch 99/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9599 - loss: 0.1084 - val_accuracy: 0.7674 - val_loss: 1.0514\n",
            "Epoch 100/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9685 - loss: 0.0953 - val_accuracy: 0.7674 - val_loss: 1.0281\n",
            "Epoch 101/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9548 - loss: 0.1394 - val_accuracy: 0.7396 - val_loss: 1.0249\n",
            "Epoch 102/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9563 - loss: 0.1061 - val_accuracy: 0.7639 - val_loss: 0.9880\n",
            "Epoch 103/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9762 - loss: 0.0800 - val_accuracy: 0.7465 - val_loss: 1.0519\n",
            "Epoch 104/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9427 - loss: 0.1653 - val_accuracy: 0.7535 - val_loss: 1.0758\n",
            "Epoch 105/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9641 - loss: 0.1049 - val_accuracy: 0.7014 - val_loss: 1.0941\n",
            "Epoch 106/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9551 - loss: 0.1353 - val_accuracy: 0.7500 - val_loss: 1.0343\n",
            "Epoch 107/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9627 - loss: 0.1257 - val_accuracy: 0.7326 - val_loss: 1.1418\n",
            "Epoch 108/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9514 - loss: 0.1335 - val_accuracy: 0.7569 - val_loss: 0.9643\n",
            "Epoch 109/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9738 - loss: 0.0988 - val_accuracy: 0.7743 - val_loss: 0.9414\n",
            "Epoch 110/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9680 - loss: 0.0817 - val_accuracy: 0.7569 - val_loss: 1.0145\n",
            "Epoch 111/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9601 - loss: 0.1112 - val_accuracy: 0.7743 - val_loss: 1.0238\n",
            "Epoch 112/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9502 - loss: 0.1400 - val_accuracy: 0.7708 - val_loss: 1.0668\n",
            "Epoch 113/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9764 - loss: 0.0946 - val_accuracy: 0.7708 - val_loss: 1.0452\n",
            "Epoch 114/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9680 - loss: 0.0935 - val_accuracy: 0.7917 - val_loss: 1.0304\n",
            "Epoch 115/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9718 - loss: 0.1085 - val_accuracy: 0.7639 - val_loss: 1.0720\n",
            "Epoch 116/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9844 - loss: 0.0646 - val_accuracy: 0.7639 - val_loss: 1.0428\n",
            "Epoch 117/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9630 - loss: 0.1022 - val_accuracy: 0.7639 - val_loss: 1.0744\n",
            "Epoch 118/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9640 - loss: 0.1120 - val_accuracy: 0.7569 - val_loss: 1.0413\n",
            "Epoch 119/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9697 - loss: 0.0890 - val_accuracy: 0.7326 - val_loss: 1.1728\n",
            "Epoch 120/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9723 - loss: 0.0968 - val_accuracy: 0.7465 - val_loss: 1.1164\n",
            "Epoch 121/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9670 - loss: 0.1086 - val_accuracy: 0.7465 - val_loss: 1.1452\n",
            "Epoch 122/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9603 - loss: 0.1243 - val_accuracy: 0.7188 - val_loss: 1.1535\n",
            "Epoch 123/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9733 - loss: 0.0962 - val_accuracy: 0.7396 - val_loss: 1.1845\n",
            "Epoch 124/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9590 - loss: 0.1184 - val_accuracy: 0.7361 - val_loss: 1.3162\n",
            "Epoch 125/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9510 - loss: 0.1231 - val_accuracy: 0.7604 - val_loss: 1.1504\n",
            "Epoch 126/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9790 - loss: 0.0691 - val_accuracy: 0.7465 - val_loss: 1.2190\n",
            "Epoch 127/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9557 - loss: 0.1152 - val_accuracy: 0.7431 - val_loss: 1.1336\n",
            "Epoch 128/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9738 - loss: 0.0926 - val_accuracy: 0.7326 - val_loss: 1.1539\n",
            "Epoch 129/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9645 - loss: 0.1096 - val_accuracy: 0.7639 - val_loss: 1.0858\n",
            "Epoch 130/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9719 - loss: 0.0823 - val_accuracy: 0.7639 - val_loss: 1.1426\n",
            "Epoch 131/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9483 - loss: 0.1717 - val_accuracy: 0.7604 - val_loss: 1.1224\n",
            "Epoch 132/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9619 - loss: 0.1065 - val_accuracy: 0.7396 - val_loss: 1.1316\n",
            "Epoch 133/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9628 - loss: 0.1200 - val_accuracy: 0.7639 - val_loss: 1.1073\n",
            "Epoch 134/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9699 - loss: 0.0933 - val_accuracy: 0.7222 - val_loss: 1.1874\n",
            "Epoch 135/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9760 - loss: 0.0760 - val_accuracy: 0.7500 - val_loss: 1.1313\n",
            "Epoch 136/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9683 - loss: 0.0862 - val_accuracy: 0.7326 - val_loss: 1.1917\n",
            "Epoch 137/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9702 - loss: 0.1051 - val_accuracy: 0.7257 - val_loss: 1.2116\n",
            "Epoch 138/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9670 - loss: 0.1234 - val_accuracy: 0.7292 - val_loss: 1.2110\n",
            "Epoch 139/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9574 - loss: 0.1242 - val_accuracy: 0.7465 - val_loss: 1.2595\n",
            "Epoch 140/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9639 - loss: 0.0926 - val_accuracy: 0.7396 - val_loss: 1.1352\n",
            "Epoch 141/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9717 - loss: 0.0853 - val_accuracy: 0.7569 - val_loss: 1.0663\n",
            "Epoch 142/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9674 - loss: 0.1035 - val_accuracy: 0.7778 - val_loss: 0.9882\n",
            "Epoch 143/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9648 - loss: 0.1040 - val_accuracy: 0.7500 - val_loss: 1.0916\n",
            "Epoch 144/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9633 - loss: 0.1110 - val_accuracy: 0.7396 - val_loss: 1.0389\n",
            "Epoch 145/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9738 - loss: 0.0856 - val_accuracy: 0.7639 - val_loss: 1.1074\n",
            "Epoch 146/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9793 - loss: 0.0528 - val_accuracy: 0.7326 - val_loss: 1.0577\n",
            "Epoch 147/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9697 - loss: 0.1002 - val_accuracy: 0.7535 - val_loss: 1.0498\n",
            "Epoch 148/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9727 - loss: 0.1088 - val_accuracy: 0.7465 - val_loss: 1.1075\n",
            "Epoch 149/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9719 - loss: 0.0776 - val_accuracy: 0.7257 - val_loss: 1.2048\n",
            "Epoch 150/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9842 - loss: 0.0568 - val_accuracy: 0.7396 - val_loss: 1.1147\n",
            "Epoch 151/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9749 - loss: 0.0835 - val_accuracy: 0.7292 - val_loss: 1.2502\n",
            "Epoch 152/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9551 - loss: 0.1348 - val_accuracy: 0.7326 - val_loss: 1.2109\n",
            "Epoch 153/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9649 - loss: 0.0897 - val_accuracy: 0.7465 - val_loss: 1.1695\n",
            "Epoch 154/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9711 - loss: 0.0743 - val_accuracy: 0.7326 - val_loss: 1.2185\n",
            "Epoch 155/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9679 - loss: 0.1068 - val_accuracy: 0.7361 - val_loss: 1.1743\n",
            "Epoch 156/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9682 - loss: 0.0848 - val_accuracy: 0.7500 - val_loss: 1.2638\n",
            "Epoch 157/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9691 - loss: 0.0920 - val_accuracy: 0.7639 - val_loss: 1.1460\n",
            "Epoch 158/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9763 - loss: 0.0839 - val_accuracy: 0.7222 - val_loss: 1.2619\n",
            "Epoch 159/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9832 - loss: 0.0638 - val_accuracy: 0.7292 - val_loss: 1.1809\n",
            "Epoch 160/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9683 - loss: 0.0976 - val_accuracy: 0.7396 - val_loss: 1.1038\n",
            "Epoch 161/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9664 - loss: 0.1252 - val_accuracy: 0.7326 - val_loss: 1.1729\n",
            "Epoch 162/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9721 - loss: 0.0800 - val_accuracy: 0.7535 - val_loss: 1.1415\n",
            "Epoch 163/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9685 - loss: 0.0732 - val_accuracy: 0.7500 - val_loss: 1.1972\n",
            "Epoch 164/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9778 - loss: 0.0742 - val_accuracy: 0.7708 - val_loss: 1.1190\n",
            "Epoch 165/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9746 - loss: 0.0687 - val_accuracy: 0.7500 - val_loss: 1.1132\n",
            "Epoch 166/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9702 - loss: 0.0837 - val_accuracy: 0.7569 - val_loss: 1.0228\n",
            "Epoch 167/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9726 - loss: 0.0853 - val_accuracy: 0.7847 - val_loss: 0.9790\n",
            "Epoch 168/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9770 - loss: 0.0848 - val_accuracy: 0.7604 - val_loss: 1.0950\n",
            "Epoch 169/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9813 - loss: 0.0595 - val_accuracy: 0.7639 - val_loss: 1.0696\n",
            "Epoch 170/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9756 - loss: 0.0619 - val_accuracy: 0.7465 - val_loss: 1.1022\n",
            "Epoch 171/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9811 - loss: 0.0604 - val_accuracy: 0.7604 - val_loss: 1.0557\n",
            "Epoch 172/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9718 - loss: 0.0932 - val_accuracy: 0.7743 - val_loss: 1.0597\n",
            "Epoch 173/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9690 - loss: 0.0923 - val_accuracy: 0.7361 - val_loss: 1.1082\n",
            "Epoch 174/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9776 - loss: 0.0598 - val_accuracy: 0.7465 - val_loss: 1.0655\n",
            "Epoch 175/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9729 - loss: 0.0883 - val_accuracy: 0.7569 - val_loss: 1.0830\n",
            "Epoch 176/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9714 - loss: 0.0779 - val_accuracy: 0.7639 - val_loss: 1.0812\n",
            "Epoch 177/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9633 - loss: 0.1125 - val_accuracy: 0.7222 - val_loss: 1.2007\n",
            "Epoch 178/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9645 - loss: 0.1069 - val_accuracy: 0.7951 - val_loss: 0.9492\n",
            "Epoch 179/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9583 - loss: 0.1158 - val_accuracy: 0.7500 - val_loss: 1.0853\n",
            "Epoch 180/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9666 - loss: 0.0993 - val_accuracy: 0.7604 - val_loss: 1.1118\n",
            "Epoch 181/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9659 - loss: 0.0822 - val_accuracy: 0.7535 - val_loss: 1.1489\n",
            "Epoch 182/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9848 - loss: 0.0783 - val_accuracy: 0.7535 - val_loss: 1.1613\n",
            "Epoch 183/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9740 - loss: 0.0993 - val_accuracy: 0.7535 - val_loss: 1.1268\n",
            "Epoch 184/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9702 - loss: 0.0650 - val_accuracy: 0.7604 - val_loss: 1.1400\n",
            "Epoch 185/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9702 - loss: 0.0702 - val_accuracy: 0.7431 - val_loss: 1.1712\n",
            "Epoch 186/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9669 - loss: 0.1066 - val_accuracy: 0.7743 - val_loss: 1.1421\n",
            "Epoch 187/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9714 - loss: 0.0886 - val_accuracy: 0.7639 - val_loss: 1.1579\n",
            "Epoch 188/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9782 - loss: 0.0657 - val_accuracy: 0.7708 - val_loss: 1.1620\n",
            "Epoch 189/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9812 - loss: 0.0587 - val_accuracy: 0.7778 - val_loss: 1.1348\n",
            "Epoch 190/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9807 - loss: 0.0726 - val_accuracy: 0.7569 - val_loss: 1.0961\n",
            "Epoch 191/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9795 - loss: 0.0558 - val_accuracy: 0.7743 - val_loss: 1.1558\n",
            "Epoch 192/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9731 - loss: 0.0576 - val_accuracy: 0.7639 - val_loss: 1.2350\n",
            "Epoch 193/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9673 - loss: 0.1128 - val_accuracy: 0.7431 - val_loss: 1.1992\n",
            "Epoch 194/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9792 - loss: 0.0535 - val_accuracy: 0.7431 - val_loss: 1.2399\n",
            "Epoch 195/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9755 - loss: 0.0606 - val_accuracy: 0.7708 - val_loss: 1.2200\n",
            "Epoch 196/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9667 - loss: 0.0896 - val_accuracy: 0.7743 - val_loss: 1.1304\n",
            "Epoch 197/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9658 - loss: 0.0896 - val_accuracy: 0.7569 - val_loss: 1.1918\n",
            "Epoch 198/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9812 - loss: 0.0595 - val_accuracy: 0.7465 - val_loss: 1.2051\n",
            "Epoch 199/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9733 - loss: 0.0795 - val_accuracy: 0.7431 - val_loss: 1.2958\n",
            "Epoch 200/200\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9660 - loss: 0.1032 - val_accuracy: 0.7465 - val_loss: 1.2847\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss , acc =model.evaluate(X_test,y_test)\n",
        "print(\"Loss: \",loss)\n",
        "print(\"Accuracy: \",acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7jYAS1sIvPz",
        "outputId": "d2d009e8-bce5-41c0-dfbd-3834d84f52ae"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7419 - loss: 1.1885\n",
            "Loss:  1.2846522331237793\n",
            "Accuracy:  0.7465277910232544\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "jyfZU4FHZMD6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss , acc =model.evaluate(X_test,y_test)\n",
        "print(\"Loss: \",loss)\n",
        "print(\"Accuracy: \",acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sd0rDlYEZzhe",
        "outputId": "af6c6776-df93-4634-fcf6-d476fe6bccde"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7419 - loss: 1.1885 \n",
            "Loss:  1.2846522331237793\n",
            "Accuracy:  0.7465277910232544\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PfGBzjj-f3UO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"emotion_model.h5\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eHx5Otn9JBAB",
        "outputId": "c9994692-bafc-4709-9fe9-7ee5d60481b4"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/Suprise.m4a\"\n",
        "\n",
        "sample = extract_mfcc(file_path)\n",
        "sample = np.expand_dims(sample, axis=0)\n",
        "\n",
        "prediction = model.predict(sample)\n",
        "emotion = encoder.inverse_transform([np.argmax(prediction)])\n",
        "\n",
        "print(\"Predicted Emotion:\", emotion[0])\n"
      ],
      "metadata": {
        "id": "st1dV2WnJW3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/happy2.wav.m4a\"\n",
        "\n",
        "sample = extract_mfcc(file_path)\n",
        "sample = np.expand_dims(sample, axis=0)\n",
        "\n",
        "prediction = model.predict(sample)\n",
        "emotion = encoder.inverse_transform([np.argmax(prediction)])\n",
        "\n",
        "print(\"Predicted Emotion:\", emotion[0])"
      ],
      "metadata": {
        "id": "rGYbw3yVP3Qo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C295MSv3VmJ1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}